7.2 Viewing File Contents
cat | less | tail | more | head
cat -n numbering output

7.3 Splitting Files
the split command can take one file and split it into multiple files.

By default, the new files will be named with a prefix of x and an alphabetical suffix of aa, ab, etc.:

sysadmin@localhost:~/Documents$ split longfile.txt
sysadmin@localhost:~/Documents$ ls                                              
School            alpha.txt    linux.txt     profile.txt   xac  xai             
Work              animals.txt  longfile.txt  red.txt       xad  xaj             
adjectives.txt    food.txt     newhome.txt   spelling.txt  xae  xak             
alpha-first.txt   hello.sh     numbers.txt   words         xaf                  
alpha-second.txt  hidden.txt   os.csv        xaa           xag                  
alpha-third.txt   letters.txt  people.csv    xab           xah

sysadmin@localhost:~/Documents$ split longfile.txt file.

The -d option will allow for the split files to have a numeric suffix instead of a default alphabetic suffix. If -d is added to the previous command, the resulting file names would be:

sysadmin@localhost:~/Documents$ split -d longfile.txt file.

By default, the split command will break apart a file into 1,000 line chunks. The first 1,000 lines of the original file will go into the first file, the second 1,000 lines will go into the second file, etc. The above file longfile.txt splits into 11 files, meaning it is approximately 11,000 lines long.

The -l option can be used to specify the number of lines to split upon. Alternatively, the -b option may be used to specify the maximum number of bytes to use per file.

7.4 Numbering the Output of Files
The nl command will number the lines of its output.

nl -ba newhome.txt

the option -ba may cause some confusion as it is really just one option, not two. The -b option is the --body-numbering option, abbreviated in its short version as -b. The a is actually an argument that means number all lines. In other words, the command could also be executed:

nl -b a newhome.txt

It is also possible to number lines using the cat -n command with the -n option, which numbers every line by default.

7.5 Displaying the Beginning of a File
head
head -3 alpha.txt
head -n3 alpha.txt

7.6 Displaying the End of a File
tail -n +20 alpha.txt

Consider This

Another unusual, but useful feature of the tail command is its ability to follow a file. When the tail command is executed with the -f option and a file name argument, then it will initially output the number of lines specified. Instead of exiting after displaying the lines, the tail command continues to run, following any changes in the file and displaying new content as it is added to the end of the file.

One of the main applications for this follow feature is for administrators to watch log files change while they are troubleshooting problems.

Additionally, the -F option is used when following a log file that may have been rotated or archived, and a new empty file of the same name replaces it. The -F option allows tail to notice that the underlying inode number that matches the log file name has changed, and it will continue to watch the new log file.

tail -F fileName.txt

7.7 Combining File Output
The paste command will merge the lines of one or more files, line by line, separating them with a tab as a delimiter (separator) by default.

It is also possible to use other characters as delimiters. For instance, if the intent is to create a file that a spreadsheet could easily open, a comma would be chosen as the delimiter. The -d option is used to specify the delimiter.

paste -d , numbers.txt letters.txt



join [OPTION]... FILE1 FILE2

the join command is able to combine two files. Instead of simply going line by line through the files, the join command matches the values of fields to determine which lines to combine. In other words, it will join files based on a common field between the files.

Consider This

For those familiar with Structured Query Language (SQL), the join command is similar to the SQL join statement, which combines records from two tables of related tables by matching values in joined fields.


sysadmin@localhost:~/Documents$ cat adjectives.txt
1 golden
2 honey
3 fruit
4 grey
5 bald
sysadmin@localhost:~/Documents$ cat animals.txt
1 retriever 
2 badger
3 bat
4 wolf
5 eagle


sysadmin@localhost:~/Documents$ join adjectives.txt animals.txt
1 golden retriever
2 honey badger
3 fruit bat
4 grey wolf
5 bald eagle

Use the -t option to specify an alternate delimiter. For example, if two spreadsheets were exported into comma separated value .csv files, join could use those commas to distinguish one field from another.

The next example illustrates a more advanced use of the join command. Two files, people.csv and os.csv., will be combined by the join command using data that isn't in the first field.

sysadmin@localhost:~/Documents$ cat people.csv
Dennis,Richie
Andrew,Tanenbaum
Ken,Thompson
Linus,Torvalds
sysadmin@localhost:~/Documents$ cat os.csv
1970,Unix,Richie
1987,Minix,Tanenbaum
1970,Unix,Thompson
1991,Linux,Torvalds
The following join command will join the files according to the field containing last names:

join -1 2 -2 3 -t',' people.csv os.csv
To specify that the join field for the first file is the second field, -1 2 is used. The -1 option means "field of the first file" and the 2 argument means "the second field".

To specify that the join field for the second file is the third field, -2 3 is used. The -2 option means "field of the second file" and the 3 argument means "the third field".

These files also use a delimiter that is neither a tab nor a space, so the delimiter is specified as a comma , character with the -t',' option:

sysadmin@localhost:~/Documents$ join -1 2 -2 3 -t',' people.csv os.csv
Richie,Dennis,1970,Unix
Tanenbaum,Andrew,1987,Minix
Thompson,Ken,1970,Unix
Torvalds,Linus,1991,Linux

7.8 Command Line Pipes
COMMAND 1 | COMMAND 2 | COMMAND 3 ...

7.9 Extract Fields in a File
The cut command extracts fields of information from a text file.

The default field separator is either a space or tab; this can be modified with the delimiter -d option. Use the -f option to specify a list of comma separated field numbers to display or a hyphenated range of fields to display.

To extract certain fields from the /etc/passwd file, specify the delimiter using the colon character as an argument to the -d option. If only fields 1,5,6, and 7 were important, they could be extracted using the following command:

head -1 /etc/passwd | cut -d: -f1,5,6,7
root:root:/root:/bin/bash

head -1 /etc/passwd | cut -d: -f1,5-7

Given a file that has fields at fixed character positions, the cut command can be used to extract the characters one at a time by using the character -c option followed by a range.

For example, in the /var/syslog file; the first fifteen characters specify a timestamp. To extract only those characters from the text, specify 1 through 15:

sysadmin@localhost:~/Documents$ tail /var/log/syslog | cut -c1-15
Jul 20 15:17:01
Jul 20 15:59:02
Jul 20 16:17:01
Jul 20 16:41:22
Jul 20 16:59:02
Jul 20 17:17:01
Jul 20 17:59:02
Jul 20 18:17:01
Jul 20 18:59:02
Jul 20 19:17:01

7.10 Sort File Output
The sort command is used to display a file sorted on a specific field of data.

Using sort with no options on people.csv results in the lines being sorted in ASCII order, which is similar to alphabetical order:

sysadmin@localhost:~/Documents$ sort people.csv

This command is able to sort using any field, the same way that a spreadsheet is able to sort by any column. By default, sort breaks up each line of a file into fields using whitespace (tabs or spaces) as delimiters. To specify an alternate delimiter, use the -t option. To specify the fields to sort from first to last, use one or more -k options. In the following example, the os.csv file is sorted based on the second field of data, using the comma , character as a delimiter:

sysadmin@localhost:~/Documents$ sort -t',' -k2 os.csv
1991,Linux,Torvalds
1987,Minix,Tanenbaum
1970,Unix,Richie
1970,Unix,Thompson

While it is possible to sort the first field of os.csv using the ASCII ordering, a numerical sort makes more sense. In order to have the sort command treat a field numerically, add an n as an argument to the -k option for that key field specification. Be aware in the following example the -k option has two arguments, the 1 indicates the first field, and the n specifies sorting that field numerically:

sysadmin@localhost:~/Documents$ sort -t',' -k1n os.csv
1970,Unix,Richie
1970,Unix,Thompson
1987,Minix,Tanenbaum
1991,Linux,Torvalds
To reverse the sort direction from ascending to descending, add an r argument to the key field specification:

sysadmin@localhost:~/Documents$ sort -t',' -k1nr os.csv

sort unique
sort -u 

7.11 Remove Duplicate Lines in a File
The uniq command does what the unique -u option did with the sort command. Unlike the sort command, which rearranges the rows consecutively before eliminating duplicates, the uniq command will only eliminate duplicates if they are already consecutive lines. If the sort command is already being used to rearrange the duplicates into consecutive order, then why not just use the -u option to eliminate duplicates?

There are a couple of reasons to use the uniq command instead of the sort -u command. First, there may be times when the lines should not be sorted first. The uniq command can simply remove lines that are currently consecutive.

Second, the count -c option to the uniq command outputs the number of duplicates that were counted (a feature that the sort command lacks):

‌⁠​​⁠​ 
sysadmin@localhost:~/Documents$ cut -f7 -d: /etc/passwd | sort | uniq -c
    3 /bin/bash
    1 /bin/sync                                                    
    23 /usr/sbin/nologin

7.12 Display File Contents in Various Formats
The od command can output data in several different formats. It produces an octal dump by default (hence the name od). One use of this command is to display the contents of a file when it contains non-printable characters, such as control characters.

Single Option	Option with Argument	Meaning
-a	-t a	Named characters, ignoring high bit
-b	-t o1	Octal bytes
-c	-t c	ASCII characters or backslash escapes
-d	-t u2	Unsigned decimal 2-byte units
-f	-t fF	Floats
-i	-t dI	Decimal integers
-l	-t dL	Decimal longs
-o	-t o2	Octal 2-byte units
-s	-t d2	Decimal 2-byte units
-x	-t x2	Hexadecimal 2-byte units

t seems straight-forward enough, but there are non-printable control characters \r causing cat to return to the beginning of the first line. This is where od comes in handy. Use the -c option to examine ASCII characters:

sysadmin@localhost:~/Documents$ od -c hidden.txt
0000000    T   h   i   s      \r   i   s      \r   a      \r   h   i   d
0000020    d   e   n      \r   m   e   s   s   a   g   e      \r   N   G
0000040    D       L   P   I   C   -   1       C   u   r   r   i   c   u
0000060    l   u   m      \n   I   s       T   h   e       B   e   s   t
0000100    .  \n  \n                                                    
0000103

od can display raw file content in octal form. It also supports hexadecimal and decimal output. This can be very useful when analyzing a precompiled binary, such as a virus:

Two other options control where the od command will read its data from the file:

Option	Function
-j	Specify how many bytes to skip from the input.
-N	Specify the total number of bytes the od command will read from the file.
See how these options work with the same hidden.txt file from the previous example, skipping thirteen bytes and displaying only fifteen bytes total:

sysadmin@localhost:~/Documents$ od -j 13 -N 15 -c hidden.txt
0000015    h   i   d   d   e   n      \r   m   e   s   s   a   g   e
0000034
Additional options that are used to affect the output of the od command:

Option	Function
-w	Specify the width in bytes to output next to the offset address. By default, the width will be sixteen bytes.
The -A option has several ways to specify the offset address to the left of the data as the formatting options covered earlier:

Option	Function
-An	Prevents the od command from outputting the offset address to the left of the data.
-Ad	Outputs file offsets using decimal addresses.
-Ax	Outputs file offsets using hexadecimal addresses.
File offsets are non-negative integers that specify a point within a file that is a specific number of bytes from a known position. For example, an offset of 64 from the beginning of a file would the denote 65th bit in the file. Offsets are a way to specify a particular piece of information located within a data file. They can be useful for dealing with files that are open or have been damaged, or in computer forensics for recovering deleted information.

The following example, the od command displays the file with a width of eight bytes of data, the offset address suppressed, and the bytes of data being displayed as ASCII characters:

sysadmin@localhost:~/Documents$ od -j 13 -N 15 -c -w8 -An ./hidden.txt
   h   i   d   d   e   n  	\r
   m   e   s   s   a   g   e

7.13 Translate File Characters
The tr command can be used to translate from one set of characters to another.

cat alpha-first.txt | tr 'a-z' 'A-Z'

sysadmin@localhost:~/Documents$ cat alpha-first.txt | tr 'aeiou' '@&1*^'
A 1s f*r An1m@l   
B 1s f*r B&@r
C 1s f*r C@t
D 1s f*r D*g
E 1s f*r El&ph@nt
F 1s f*r Fl*w&r

to eliminate duplicates, use the -s option to squeeze repeats of characters from the first set:

sysadmin@localhost:~/Documents$ echo 'aaaaaappleeeeee' | tr -s 'ae'
apple
Using the -d option will delete the characters in the first set:

sysadmin@localhost:~/Documents$ cat alpha-first.txt | tr -d 'AEIOUaeiou'
 s fr nml  
B s fr Br
C s fr Ct
D s fr Dg
 s fr lphnt
F s fr Flwr

7.14 Stream Editor Command
The stream editor sed command is a non-interactive editor that can be used to modify text.

o do a simple search and replace operation, use the following script, or expression. This will search for the pattern between the first two slashes, and if it finds that text, then it replaces it with what is specified between the last two slashes:

s/PATTERN/REPLACEMENT/
In the alpha-first.txt file, to replace the word Animal with the word Apple, execute the following command:

sysadmin@localhost:~/Documents$ sed 's/Animal/Apple/' alpha-first.txt
A is for Apple
B is for Bear
C is for Cat
D is for Dog
E is for Elephant
F is for Flower

Unlike most filter commands, the sed command can modify the original file by using the -i option.The -i option allows for an optional argument, which will be an extension added to the original file. The result is a new file which is a copy of the original file. For example, if you wanted to backup the original file as alpha-first.txt.original file, execute the following:

sysadmin@localhost:~/Documents$ sed -i'.original' 's/Animal/Apple/' alpha-first.txt
sysadmin@localhost:~/Documents$ cat alpha-first.txt
A is for Apple
B is for Bear
C is for Cat
D is for Dog
E is for Elephant
F is for Flower
sysadmin@localhost:~/Documents$ cat alpha-first.txt.original
A is for Animal
B is for Bear
C is for Cat
D is for Dog
E is for Elephant
F is for Flower

The Global Modifier

s/PATTERN/REPLACEMENT/g
For example, consider the food.txt text file:

sysadmin@localhost:~/Documents$ cat food.txt
Food is good.
The following example will only replace the first occurrence of the oo pattern with the 00 pattern:

sysadmin@localhost:~/Documents$ sed 's/oo/00/' food.txt
F00d is good.
If you want to replace every occurrence of oo with 00, add the g modifier:

sysadmin@localhost:~/Documents$ sed 's/oo/00/g' food.txt
F00d is g00d.

The sed command is also able to either insert text before a pattern or after a pattern. For this type of expression, do not use the s character before the first slash; use an insert change with the i\ expression or an append change with the a\ expression.

/PATTERN/i\TEXT\
/PATTERN/a\TEXT\
Inserting text with the i\ expression affects the line before the line containing the search term:

sysadmin@localhost:~/Documents$ sed '/is/i\Hello' food.txt
Hello
Food is good.
Appending text with the a\ expression affects the line after the line containing the search term:

sysadmin@localhost:~/Documents$ sed '/is/a\Hello' food.txt
Food is good.
Hello
The sed command can also be used to search for a line of text containing a pattern and then delete the lines that match. Place the pattern to search for between two slashes followed by a d to carry out this operation:

/PATTERN/d
Notice the animals.txt file has five lines, but the following example command removes the lines that contain an a:

sysadmin@localhost:~/Documents$ cat animals.txt
1 retriever
2 badger
3 bat
4 wolf
5 eagle
sysadmin@localhost:~/Documents$ sed '/a/d' animals.txt
1 retriever
4 wolf
To change an entire line that matches a pattern to something else, use a slash, the pattern to match, another slash, c\, and then the new text.

/PATTERN/c\REPLACEMENT
For example, to change a line containing 3 to three, use the following command:

sysadmin@localhost:~/Documents$ cat numbers.txt
1
2
3
4
5
sysadmin@localhost:~/Documents$ sed '/3/c\three' numbers.txt
1
2
three
4
5
Keep in mind the entire line will be replaced, not just the matching pattern:

sysadmin@localhost:~/Documents$ sed '/3/c\three' animals.txt
1 retriever
2 badger
three
4 wolf
5 eagle
The sed command normally parses only one expression to filter text. To use multiple expressions, use a -e option with each expression to modify the file.

Notice that the order in which those expressions are placed makes a difference. In the first attempt, both expressions are effective, but in the second attempt, only the first is effective. After the first expression deletes all lines containing an a, the second expression doesn't have anything to do because the line that contained 3 was removed:

sysadmin@localhost:~/Documents$ sed -e '/3/c\three' -e '/a/d' animals.txt
1 retriever
three
4 wolf
sysadmin@localhost:~/Documents$ sed -e '/a/d' -e '/3/c\three' animals.txt
1 retriever
4 wolf
Note

The use of the term pattern in this section refers to one of the most powerful aspects of the sed command, its compatibility with regular expressions. In each example so far, the sed command has been using literal expressions involving alphanumeric characters like t or o or strings like three. Regular expressions can be used to create patterns for use with the sed command and many other, far more powerful commands.

Regular expressions will be covered in greater detail later in the course.

7.15 Counting Lines in a File
The wc command can be used to analyze a text file. By default, wc counts the number of lines, words, and byte counts in a passage and outputs this information in the following format:

lines words bytes filename

cat alpha-first.txt
A is for Apple 
B is for Bear
C is for Cat
D is for Dog
E is for Elephant
F is for Flower

wc alpha-first.txt
 6 24 90 alpha-first.txt

 the -l option was used to count the number of lines. In the second example, the -w option was used to count the number of words. Finally, the -m option indicates the number of characters.

-c is used to count the number of bytes.

-L returns the maximum line length in the file:





















m






